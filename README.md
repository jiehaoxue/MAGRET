# MAGRET: A Dataset for Multi-Target Visual Grounding in Remote Sensing Images with Cross-Modal Annotations

![Frame](https://img.shields.io/badge/Frame-pytorch-important.svg)
![license](https://img.shields.io/badge/License-GPLv3-brightgreen.svg)

![MAGRET](MAGRET.png)

This repository contains the official implementation and datasets for the paper "MAGRET: A Dataset for Multi-Target Visual Grounding in Remote Sensing Images with Cross-Modal Annotations".

## Installation

MAGRET needs to be installed first before use. The code requires `python>=3.12`, as well as `torch>=2.6.0` and `torchvision>=0.21.0`. Please follow the instructions [here](https://pytorch.org/get-started/locally/) to install both PyTorch and TorchVision dependencies. You can install RSAM on a GPU machine using:

### Dataset
[MAGRET](https://huggingface.co/datasets/xuejiehao/MAGRET/tree/main)





